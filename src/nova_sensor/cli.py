#!/usr/bin/env python3
"""
Nova CLI - å‘½ä»¤è¡Œä»‹é¢
æä¾› nova å·¥å…·åŒ…çš„å‘½ä»¤è¡Œè¨ªå•
"""

import argparse
import sys
from pathlib import Path
from typing import Optional
import importlib.util

from .nova_memory_monitor import (
    NovaMemoryMonitor,
    create_monitor_with_config,
    monitor_memory_continuous
)
from .performance_tester import (
    NovaPerformanceTester,
    performance_test,
    compare_with_baseline,
    quick_benchmark,
    memory_profile,
    get_system_info
)


def create_parser() -> argparse.ArgumentParser:
    """å‰µå»ºå‘½ä»¤è¡Œåƒæ•¸è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="Nova Sensor - é«˜æ€§èƒ½é–‹ç™¼å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  nova-sensor monitor                    # å•Ÿå‹•è¨˜æ†¶é«”ç›£æ§
  nova-sensor monitor --config config.json  # ä½¿ç”¨è‡ªå®šç¾©é…ç½®
  nova-sensor monitor --continuous 300   # é€£çºŒç›£æ§ 5 åˆ†é˜
  nova-sensor test                       # é‹è¡Œæ¸¬è©¦å¥—ä»¶
  nova-sensor performance                # é‹è¡Œé è¨­æ•ˆèƒ½æ¸¬è©¦
  nova-sensor performance --system-info  # é¡¯ç¤ºç³»çµ±è³‡è¨Š
  nova-sensor performance --module test.py --function my_func  # æ¸¬è©¦ç‰¹å®šå‡½æ•¸
  nova-sensor performance --iterations 1000  # è‡ªå®šç¾©è¿­ä»£æ¬¡æ•¸
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # è¨˜æ†¶é«”ç›£æ§å‘½ä»¤
    monitor_parser = subparsers.add_parser(
        'monitor',
        help='è¨˜æ†¶é«”ç›£æ§åŠŸèƒ½'
    )
    monitor_parser.add_argument(
        '--config', '-c',
        type=str,
        default='memory_config.json',
        help='è¨­å®šæª”æ¡ˆè·¯å¾‘ (é è¨­: memory_config.json)'
    )
    monitor_parser.add_argument(
        '--continuous', '-t',
        type=int,
        nargs='?',
        const=300,
        help='é€£çºŒç›£æ§ç§’æ•¸ (é è¨­: 300ç§’)'
    )
    monitor_parser.add_argument(
        '--interval', '-i',
        type=int,
        default=30,
        help='ç›£æ§é–“éš”ç§’æ•¸ (é è¨­: 30ç§’)'
    )

    # æ¸¬è©¦å‘½ä»¤
    test_parser = subparsers.add_parser(
        'test',
        help='é‹è¡Œæ¸¬è©¦å¥—ä»¶'
    )
    test_parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è©³ç´°è¼¸å‡º'
    )

    # æ•ˆèƒ½æ¸¬è©¦å‘½ä»¤
    perf_parser = subparsers.add_parser(
        'performance',
        help='æ•ˆèƒ½æ¸¬è©¦å’ŒåŸºæº–æ¸¬è©¦åŠŸèƒ½'
    )
    perf_parser.add_argument(
        '--iterations', '-n',
        type=int,
        default=100,
        help='åŸºæº–æ¸¬è©¦è¿­ä»£æ¬¡æ•¸ (é è¨­: 100)'
    )
    perf_parser.add_argument(
        '--output', '-o',
        type=str,
        default='performance_results',
        help='è¼¸å‡ºç›®éŒ„ (é è¨­: performance_results)'
    )
    perf_parser.add_argument(
        '--function', '-f',
        type=str,
        help='è¦æ¸¬è©¦çš„å‡½æ•¸åç¨± (ç”¨æ–¼åŸºæº–æ¸¬è©¦)'
    )
    perf_parser.add_argument(
        '--module', '-m',
        type=str,
        help='è¦è¼‰å…¥çš„æ¸¬è©¦æ¨¡çµ„è·¯å¾‘'
    )
    perf_parser.add_argument(
        '--compare', '-c',
        type=str,
        nargs=2,
        metavar=('BASELINE', 'OPTIMIZED'),
        help='æ¯”è¼ƒå…©å€‹å‡½æ•¸çš„æ•ˆèƒ½ (åŸºæº–å‡½æ•¸, å„ªåŒ–å‡½æ•¸)'
    )
    perf_parser.add_argument(
        '--system-info', '-s',
        action='store_true',
        help='é¡¯ç¤ºç³»çµ±è³‡è¨Š'
    )
    perf_parser.add_argument(
        '--memory-profile', '-p',
        action='store_true',
        help='åŸ·è¡Œè¨˜æ†¶é«”å‰–æ'
    )

    return parser


def run_monitor(args: argparse.Namespace) -> int:
    """é‹è¡Œè¨˜æ†¶é«”ç›£æ§"""
    try:
        print("ğŸš€ å•Ÿå‹• Nova è¨˜æ†¶é«”ç›£æ§å™¨")

        # å‰µå»ºç›£æ§å™¨
        monitor = create_monitor_with_config(args.config)
        print(f"âœ… è¨­å®šè¼‰å…¥æˆåŠŸ: {args.config}")

        if args.continuous:
            # é€£çºŒç›£æ§æ¨¡å¼
            print(f"ğŸ”„ é–‹å§‹é€£çºŒç›£æ§ {args.continuous} ç§’...")
            result = monitor_memory_continuous(
                monitor,
                interval=args.interval,
                duration=args.continuous
            )

            print("ğŸ“Š ç›£æ§å®Œæˆçµ±è¨ˆ:")
            print(f"   ç¸½æª¢æŸ¥æ¬¡æ•¸: {result['check_count']}")
            print(f"   æ¸…ç†æ¬¡æ•¸: {result['cleanup_count']}")
            print(f"   å¹³å‡ CPU ä½¿ç”¨ç‡: {result['avg_cpu_percent']:.1f}%")
        else:
            # å–®æ¬¡ç›£æ§æ¨¡å¼
            stats = monitor.get_memory_stats()
            monitor.print_stats()

            cleanup_level = monitor.should_cleanup()
            if cleanup_level:
                duration = monitor.cleanup_memory(cleanup_level)
                print(f"ğŸ§¹ å·²åŸ·è¡Œ {cleanup_level} ç´šåˆ¥æ¸…ç†ï¼Œè€—æ™‚ {duration:.3f} ç§’")
            else:
                print("âœ… è¨˜æ†¶é«”ä½¿ç”¨æ­£å¸¸ï¼Œç„¡éœ€æ¸…ç†")

        return 0

    except FileNotFoundError:
        print(f"âŒ è¨­å®šæª”æ¡ˆä¸å­˜åœ¨: {args.config}")
        print("ğŸ’¡ æç¤º: è«‹æª¢æŸ¥æª”æ¡ˆè·¯å¾‘ï¼Œæˆ–ä½¿ç”¨é è¨­è¨­å®šé‹è¡Œ")
        return 1
    except Exception as e:
        print(f"âŒ ç›£æ§éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1


def run_tests(args: argparse.Namespace) -> int:
    """é‹è¡Œæ¸¬è©¦å¥—ä»¶"""
    try:
        print("ğŸ§ª é‹è¡Œ Nova æ¸¬è©¦å¥—ä»¶")

        # åŒ¯å…¥æ¸¬è©¦æ¨¡çµ„
        import subprocess
        import sys

        # é‹è¡Œæ¸¬è©¦è…³æœ¬
        test_script = Path(__file__).parent / "test_nova_memory_monitor.py"
        if not test_script.exists():
            print(f"âŒ æ¸¬è©¦è…³æœ¬ä¸å­˜åœ¨: {test_script}")
            return 1

        cmd = [sys.executable, str(test_script)]
        if args.verbose:
            cmd.append("--verbose")

        result = subprocess.run(cmd, cwd=Path(__file__).parent)

        if result.returncode == 0:
            print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        else:
            print(f"âŒ æ¸¬è©¦å¤±æ•—ï¼Œé€€å‡ºç¢¼: {result.returncode}")

        return result.returncode

    except Exception as e:
        print(f"âŒ é‹è¡Œæ¸¬è©¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1


def run_performance(args: argparse.Namespace) -> int:
    """é‹è¡Œæ•ˆèƒ½æ¸¬è©¦"""
    try:
        print("ğŸš€ å•Ÿå‹• Nova æ•ˆèƒ½æ¸¬è©¦å™¨")

        tester = NovaPerformanceTester(args.output)

        if args.system_info:
            # é¡¯ç¤ºç³»çµ±è³‡è¨Š
            print("ğŸ“Š ç³»çµ±è³‡è¨Š:")
            system_info = get_system_info()
            for key, value in system_info.items():
                if isinstance(value, float):
                    print(f"   {key}: {value:.2f}")
                else:
                    print(f"   {key}: {value}")
            return 0

        if args.module:
            # è¼‰å…¥æ¸¬è©¦æ¨¡çµ„
            print(f"ğŸ“¦ è¼‰å…¥æ¸¬è©¦æ¨¡çµ„: {args.module}")
            try:
                spec = importlib.util.spec_from_file_location("test_module", args.module)
                if spec is None:
                    print(f"âŒ ç„¡æ³•è¼‰å…¥æ¨¡çµ„: {args.module}")
                    return 1

                if spec.loader is None:
                    print(f"âŒ æ¨¡çµ„è¼‰å…¥å™¨ç„¡æ•ˆ: {args.module}")
                    return 1

                test_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(test_module)

                if args.function:
                    # æ¸¬è©¦ç‰¹å®šå‡½æ•¸
                    if hasattr(test_module, args.function):
                        func = getattr(test_module, args.function)
                        print(f"ğŸ§ª æ¸¬è©¦å‡½æ•¸: {args.function}")

                        if args.memory_profile:
                            # è¨˜æ†¶é«”å‰–æ
                            profile_result = memory_profile(func)
                            print("ğŸ“Š è¨˜æ†¶é«”å‰–æçµæœ:")
                            for key, value in profile_result.items():
                                if isinstance(value, float):
                                    print(f"   {key}: {value:.6f}")
                                else:
                                    print(f"   {key}: {value}")
                            benchmark_result = None  # è¨˜æ†¶é«”å‰–ææ²’æœ‰åŸºæº–æ¸¬è©¦çµæœ
                        else:
                            # åŸºæº–æ¸¬è©¦
                            benchmark_result = quick_benchmark(func, args.iterations)
                            print("ğŸ“Š åŸºæº–æ¸¬è©¦çµæœ:")
                            print(f"   å‡½æ•¸: {benchmark_result['function_name']}")
                            print(f"   è¿­ä»£æ¬¡æ•¸: {benchmark_result['iterations']}")
                            print(f"   å¹³å‡åŸ·è¡Œæ™‚é–“: {benchmark_result['execution_time']['mean']:.6f} ç§’")
                            print(f"   å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨: {benchmark_result['memory_usage']['mean'] / (1024*1024):.2f} MB")
                            print(f"   å¹³å‡ CPU ä½¿ç”¨ç‡: {benchmark_result['cpu_usage']['mean']:.2f}%")

                        # ç”Ÿæˆå ±å‘Š
                        if benchmark_result is not None:
                            tester.generate_report([benchmark_result])
                    else:
                        print(f"âŒ å‡½æ•¸ '{args.function}' åœ¨æ¨¡çµ„ä¸­ä¸å­˜åœ¨")
                        return 1
                else:
                    print("âŒ è«‹æŒ‡å®šè¦æ¸¬è©¦çš„å‡½æ•¸åç¨± (--function)")
                    return 1

            except Exception as e:
                print(f"âŒ è¼‰å…¥æ¨¡çµ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                return 1

        elif args.compare:
            # æ¯”è¼ƒå…©å€‹å‡½æ•¸
            baseline_name, optimized_name = args.compare
            print(f"ğŸ” æ•ˆèƒ½æ¯”è¼ƒ: {baseline_name} vs {optimized_name}")

            # é€™è£¡éœ€è¦å¾æ¨¡çµ„è¼‰å…¥å‡½æ•¸ï¼Œç°¡åŒ–ç‰ˆæœ¬å…ˆè·³é
            print("âš ï¸ æ¯”è¼ƒåŠŸèƒ½éœ€è¦æŒ‡å®šæ¨¡çµ„ (--module)")
            return 1

        else:
            # é è¨­æ¸¬è©¦è¨˜æ†¶é«”ç›£æ§åŠŸèƒ½
            print("ğŸ§ª é‹è¡Œé è¨­æ•ˆèƒ½æ¸¬è©¦ (è¨˜æ†¶é«”ç›£æ§)")

            from .nova_memory_monitor import NovaMemoryMonitor

            def test_memory_monitor():
                monitor = NovaMemoryMonitor()
                stats = monitor.get_memory_stats()
                return stats

            benchmark_result = quick_benchmark(test_memory_monitor, args.iterations)
            print("ğŸ“Š è¨˜æ†¶é«”ç›£æ§æ•ˆèƒ½æ¸¬è©¦çµæœ:")
            print(f"   å¹³å‡åŸ·è¡Œæ™‚é–“: {benchmark_result['execution_time']['mean']:.6f} ç§’")
            print(f"   å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨: {benchmark_result['memory_usage']['mean'] / (1024*1024):.2f} MB")
            print(f"   å¹³å‡ CPU ä½¿ç”¨ç‡: {benchmark_result['cpu_usage']['mean']:.2f}%")

            # ç”Ÿæˆå ±å‘Š
            tester.generate_report([benchmark_result])

        # ä¿å­˜çµæœ
        tester.save_results()

        print("âœ… æ•ˆèƒ½æ¸¬è©¦å®Œæˆï¼")
        return 0

    except Exception as e:
        print(f"âŒ æ•ˆèƒ½æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return 1


def main() -> int:
    """ä¸»å…¥å£é»"""
    parser = create_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    if args.command == 'monitor':
        return run_monitor(args)
    elif args.command == 'test':
        return run_tests(args)
    elif args.command == 'performance':
        return run_performance(args)
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {args.command}")
        parser.print_help()
        return 1


if __name__ == "__main__":
    sys.exit(main())